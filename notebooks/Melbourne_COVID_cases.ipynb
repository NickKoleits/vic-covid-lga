{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Victorian LGA COVID cases timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base url to scarpe\n",
    "base_url = 'https://covidlive.com.au/vic/'\n",
    "\n",
    "# read in list of Victorian LGA names\n",
    "LGAs = pd.read_csv('../data/vic_LGAs.csv')\n",
    "LGAs = LGAs['LGA'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the daily COVID data from https://covidlive.com.au/vic/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean LGA names - repalce space with hyphen to append to base url\n",
    "LGA_url = []\n",
    "for l in LGAs:\n",
    "    a = l.replace(\" \", \"-\").lower()\n",
    "    LGA_url.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape data from https://covidlive.com.au/vic/ for all LGAs\n",
    "# table structure appears to change frequently\n",
    "# may need to tweak code to account for changes in table structure \n",
    "columns = [\"Date\", \"Cumulative_cases\", \"Daily_cases\", \"LGA_name\", \"Active\" \"Active_cases_change\"]\n",
    "master_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# iterate over each LGA\n",
    "for i in LGA_url:\n",
    "    response = requests.get(base_url + i)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'DAILY-CASES-BY-LGA'})\n",
    "    \n",
    "    try:\n",
    "        table_rows = table.find_all('tr')\n",
    "        print(\"Retrieved URL \" + i)\n",
    "    except:\n",
    "        print(\"No data for URL \" + i)\n",
    "    \n",
    "    l = []\n",
    "    for tr in table_rows:\n",
    "        td = tr.find_all('td')\n",
    "        row = [tr.text for tr in td]\n",
    "        l.append(row)\n",
    "        \n",
    "    df = pd.DataFrame(l, columns=[\"Date\", \"-1\", \"Cumulative_cases\", \"-2\", \"Daily_cases\", \"Active_cases\", \"-3\", \"Active_cases_change\"])\n",
    "    del df['-1']\n",
    "    del df['-2']\n",
    "    del df['-3']\n",
    "    #del df['Active_cases']\n",
    "    df = df.drop(df.index[0])\n",
    "    df['LGA_name'] = i\n",
    "    master_df = pd.concat([master_df, df],ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete dirty columns\n",
    "# check the master dataframe\n",
    "del master_df['ActiveActive_cases_change']\n",
    "del master_df['Active_cases_change']\n",
    "master_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "covidlive.com.au formatted digits using a thousands comma which is nice for presentation, but can be a pain when scraping data. When converting to a dataframe, pandas has inferred the data as a string, not numeric. This will need to be cleaned and converted to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all commas with nothing\n",
    "master_df['Cumulative_cases'] = master_df['Cumulative_cases'].str.replace(\",\", \"\")\n",
    "master_df['Active_cases'] = master_df['Active_cases'].str.replace(\",\", \"\")\n",
    "\n",
    "# convert columns to numeric\n",
    "master_df['Cumulative_cases'] = pd.to_numeric(master_df['Cumulative_cases'])\n",
    "master_df['Active_cases'] = pd.to_numeric(master_df['Active_cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data types\n",
    "master_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check a couple of different LGAs, one single word and one with a hyphen, to ensure the data has been scraped correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a couple of LGAs to ensure data has been scraped correctly\n",
    "# check Hume\n",
    "master_df[master_df['LGA_name']== \"wyndham\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Mount-Alexander\n",
    "master_df[master_df['LGA_name']== \"mount-alexander\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I intend to use the values in the LGA name column as labels. As such, these need to be cleaned (i.e. hyphen removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LGA where space was replaced with hypen for visualisation, and covert to proper case\n",
    "master_df['LGA_name'] = master_df['LGA_name'].str.replace(\"-\", \" \").str.title()\n",
    "\n",
    "# check LGAs updated\n",
    "master_df[master_df['LGA_name'] == \"Mount Alexander\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a flag is created to indentify which LGAs are part of greater Melbourne. While this information could be scraped, it was easier to manually pull these LGAs from https://en.wikipedia.org/wiki/Local_government_areas_of_Victoria\n",
    "\n",
    "Finally, we run a quick count of LGA by region to check we've classified all LGAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add flag to each LGA indicating if it is metro or reginal\n",
    "greater_melb = ['Melbourne',\n",
    "'Port Phillip',\n",
    "'Stonnington',\n",
    "'Yarra',\n",
    "'Banyule',\n",
    "'Bayside',\n",
    "'Boroondara',\n",
    "'Darebin',\n",
    "'Glen Eira',\n",
    "'Hobsons Bay',\n",
    "'Kingston',\n",
    "'Manningham',\n",
    "'Maribyrnong',\n",
    "'Monash',\n",
    "'Moonee Valley',\n",
    "'Moreland',\n",
    "'Whitehorse',\n",
    "'Brimbank',\n",
    "'Cardinia',\n",
    "'Casey',\n",
    "'Frankston',\n",
    "'Greater Dandenong',\n",
    "'Hume',\n",
    "'Knox',\n",
    "'Maroondah',\n",
    "'Melton',\n",
    "'Mornington Peninsula',\n",
    "'Nillumbik',\n",
    "'Whittlesea',\n",
    "'Wyndham',\n",
    "'Yarra Ranges']\n",
    "\n",
    "# check count of LGA by region\n",
    "master_df[\"Region\"] = np.where(master_df[\"LGA_name\"].isin(greater_melb), \"Greater Melbourne\", \"Regional\")\n",
    "print(master_df.groupby('Region')['LGA_name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the flag has been applied to the dataframe\n",
    "master_df[master_df['Region'] == \"Greater Melbourne\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next issue is the date. Currently, the date is represented in dd-mmm format - ideally we need this in a longer format so will convert to yyyy-mm-dd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date time\n",
    "master_df['Date'] = pd.to_datetime(master_df['Date'], format='%d %b')\n",
    "master_df['Date'] = master_df['Date'].apply(lambda dt: dt.replace(year=2020))\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Shapefile\n",
    "\n",
    "The next section of the notebook brings in the shapefile used to create the base layer of the map. The shapefile was sourced from the ABS: https://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.003July%202016?OpenDocument\n",
    "\n",
    "* Read in the Victorian LGA shapefile\n",
    "* Remove administrative LGAs note used for mapping\n",
    "* Clean LGA names for merge with the master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import geopandas as gpd\n",
    "import shapefile as shp\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the shapefle of all Australian LGAs\n",
    "sf_aus = gpd.read_file('../data/AUS_LGA_SHP/LGA_2020_AUST.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_aus.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset aus shapefile to vic LGAs only\n",
    "vic_sf = sf_aus[sf_aus['STE_NAME16'] == 'Victoria']\n",
    "\n",
    "# remove LGA without polygons\n",
    "vic_sf = vic_sf[vic_sf['LGA_NAME20'] != 'Migratory - Offshore - Shipping (Vic.)']\n",
    "vic_sf = vic_sf[vic_sf['LGA_NAME20'] != 'No usual address (Vic.)']\n",
    "vic_sf = vic_sf[vic_sf['LGA_NAME20'] != 'Unincorporated Vic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove text within parentheses\n",
    "vic_sf['LGA_NAME20'] = vic_sf['LGA_NAME20'].str.replace(r\"(\\(.+\\))\", \"\")\n",
    "\n",
    "# strip remaining whitespace from LGA name \n",
    "vic_sf['LGA_NAME20'] = vic_sf['LGA_NAME20'].str.rstrip()\n",
    "\n",
    "# check LGAs have been cleaned\n",
    "vic_sf[vic_sf['LGA_NAME20'] == \"Wyndham\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the head of the dataframe\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged the COVID data with the shapefile\n",
    "\n",
    "Finally, we merge the COVID data with the VIC shapefile. This methodology was sources from the following TDS blog: https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the vic_sf and covid data\n",
    "merged = vic_sf.set_index('LGA_NAME20').join(master_df.set_index('LGA_name'))\n",
    "\n",
    "# check the (n) of rows and columns\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insepct the first few rows\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data frame\n",
    "# remove rows with missing dates\n",
    "df_plot = merged[merged['Date'].notna()]\n",
    "\n",
    "# subset to only Greater Melbourne LGAs\n",
    "df_plot = df_plot[df_plot['Region'] == 'Greater Melbourne']\n",
    "\n",
    "# subset to only included required columns\n",
    "df_plot = df_plot[['Cumulative_cases', 'Active_cases','geometry', 'Date', 'Region']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a single plot\n",
    "\n",
    "The next section creates a snapshot plot of a single date to ensure the code works to create the cumulative COID-19 case count for each LGA. The test plot below uses data from 10 August 2020 to generate a single plot.\n",
    "\n",
    "The colour scale can easily be changed to one of many matplotlib default scales. for more info see: https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html\n",
    "\n",
    "<img src=\"../images/colour_scales.png\" style=\"width:500px;height:400px;\">\n",
    "\n",
    "The name of the 'colour' variable can be edited to change to the desired colour scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the data to a specific day\n",
    "dfa = df_plot[df_plot['Date'] == '2020-08-10']\n",
    "\n",
    "# colour pallette\n",
    "colour = 'YlOrRd'\n",
    "\n",
    "# set a variable that will call whatever column we want to visualise on the map\n",
    "variable = 'Cumulative_cases'\n",
    "# set the range for the choropleth\n",
    "vmin, vmax = 0, 1600\n",
    "\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(14, 8))\n",
    "dfa.plot(column=variable, cmap=colour, linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "# remove the axis\n",
    "ax.axis('off')\n",
    "\n",
    "# add a title\n",
    "ax.set_title('Cumulative COVID-19 cases for Greater Melbourne LGAs', fontdict={'fontsize': '18','fontweight' : '3'})\n",
    "\n",
    "# create an annotation for the  data source\n",
    "ax.annotate('Data source: https://covidlive.com.au',\n",
    "           xy=(0.1, .08), xycoords='figure fraction',\n",
    "           horizontalalignment='left', verticalalignment='top',\n",
    "           fontsize=10, color='#555555')\n",
    "\n",
    "# Create colorbar as a legend\n",
    "sm = plt.cm.ScalarMappable(cmap=colour, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []\n",
    "cbar = fig.colorbar(sm)\n",
    "fig.savefig('../plots/single_plot/2020-08-10_cumulative_cases.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop to create plots for each day\n",
    "\n",
    "Finally we extract all dates from the master df dataframe. This will be used to iterate over each date and subset the dataframe to date [i]. We will generate one plot for each date and output the plot to the destinctation file folder. from there, the pots will be stitched together to create a GIF or video. \n",
    "\n",
    "Again, the bulk of the code to create plots for each day was adapted from: https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the dates in the covid data dataframe\n",
    "#master_df['Date_only'] = [d.strftime(\"%Y-%m-%d\") for d in master_df['Date']]\n",
    "\n",
    "# extract a list of the unique dates - this will be used to iterate over in the for loop below\n",
    "#dates = list(master_df['Date_only'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the covid data and the shapefile dataframes\n",
    "#merged = vic_sf.set_index('LGA_NAME20').join(master_df.set_index('LGA_name'))\n",
    "#merged = merged[merged['Region'] == 'Greater Melbourne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NAs, subset to metro, remove columns\n",
    "#df1 = merged[merged['Date'].notna()]\n",
    "#df1 = df1[df1['Region'] == 'Greater Melbourne']\n",
    "#df1 = df1[['Cumulative_cases', 'Active_cases','geometry', 'Date', 'Region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat dates \n",
    "#df1['Day'] = df1['Date'].dt.day\n",
    "#df1['Month'] = df1['Date'].dt.month\n",
    "#import calendar\n",
    "#df1['Month'] = df1['Month'].apply(lambda x: calendar.month_abbr[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start the for loop to create one map per day\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set the range for the choropleth\n",
    "vmin, vmax = 0, 1500\n",
    "output_path = '/Users/nickkoleits/Documents/Projects/covid_vic_lga/plots/cumulative_cases'\n",
    "variable = 'Cumulative_cases'\n",
    "i = 1\n",
    "\n",
    "colour = 'YlOrRd'\n",
    "\n",
    "for date in dates:\n",
    "    \n",
    "    #subset data to each day\n",
    "    data = df_plot[df_plot['Date'] == date]\n",
    "    data['Cumulative_cases'] = pd.to_numeric(data['Cumulative_cases'])\n",
    "    \n",
    "    \n",
    "    # create map, UDPATE: added plt.Normalize to keep the legend range the same for all maps\n",
    "    fig = data.plot(column=variable, cmap=colour, figsize=(15,8), linewidth=0.8, edgecolor='0.8', vmin=vmin, vmax=vmax, legend=True, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    \n",
    "    # remove axis of chart\n",
    "    fig.axis('off')\n",
    "    \n",
    "    # add a title\n",
    "    fig.set_title('Cumulative COVID-19 cases\\nGreater Melbourne - ' + str(date), fontdict={'fontsize': '20','fontweight' : '3'})\n",
    "\n",
    "    # create an annotation for the  data source\n",
    "    fig.annotate('Data source: https://covidlive.com.au',\n",
    "        xy=(0.1, .08), xycoords='figure fraction',\n",
    "        horizontalalignment='left', verticalalignment='top',\n",
    "        fontsize=10, color='#555555')\n",
    "    \n",
    "    # this will save the figure as a high-res png in the output path. you can also save as svg if you prefer.\n",
    "    filepath = os.path.join(output_path, str(date) +'_covid_cases.jpg')\n",
    "    chart = fig.get_figure()\n",
    "    chart.savefig(filepath, dpi=350)\n",
    "    print(\"Saved image: \" + output_path + str(date) +'_covid_cases.jpg')\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create another set of plots using active cases\n",
    "\n",
    "- We need to create a single plot to make sure we get all the plot features correct before running the loop. \n",
    "- Before that, we need to find the max a min values to ensure the plot colour scale is set to a sensible range - active cases and cumulative cases will have two very different ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get min and max values\n",
    "active_max = df_plot['Active_cases'].max()\n",
    "active_min = df_plot['Active_cases'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the data to a specific day\n",
    "dfa = df_plot[df_plot['Date'] == '2020-08-10']\n",
    "\n",
    "# colour pallette\n",
    "colour = 'YlOrRd'\n",
    "\n",
    "# set a variable that will call whatever column we want to visualise on the map\n",
    "variable = 'Active_cases'\n",
    "# set the range for the choropleth\n",
    "vmin, vmax = active_min, active_max\n",
    "\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(14, 8))\n",
    "dfa.plot(column=variable, cmap=colour, linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "# remove the axis\n",
    "ax.axis('off')\n",
    "\n",
    "# add a title\n",
    "ax.set_title('Cumulative COVID-19 cases for Greater Melbourne LGAs', fontdict={'fontsize': '18','fontweight' : '3'})\n",
    "\n",
    "# create an annotation for the  data source\n",
    "ax.annotate('Data source: https://covidlive.com.au',\n",
    "           xy=(0.1, .08), xycoords='figure fraction',\n",
    "           horizontalalignment='left', verticalalignment='top',\n",
    "           fontsize=10, color='#555555')\n",
    "\n",
    "# Create colorbar as a legend\n",
    "sm = plt.cm.ScalarMappable(cmap=colour, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []\n",
    "cbar = fig.colorbar(sm)\n",
    "fig.savefig('../plots/single_plot/2020-08-10_active_cases.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the for loop to create one map per day\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set the range for the choropleth\n",
    "vmin, vmax = active_min, active_max\n",
    "output_path = '../plots/active_cases'\n",
    "variable = 'Active_cases'\n",
    "i = 1\n",
    "\n",
    "colour = 'YlOrRd'\n",
    "\n",
    "for date in dates:\n",
    "    \n",
    "    #subset data to each day\n",
    "    data = df_plot[df_plot['Date'] == date]\n",
    "    data['Active_cases'] = pd.to_numeric(data['Active_cases'])\n",
    "    \n",
    "    \n",
    "    # create map, UDPATE: added plt.Normalize to keep the legend range the same for all maps\n",
    "    fig = data.plot(column=variable, cmap=colour, figsize=(15,8), linewidth=0.8, edgecolor='0.8', vmin=vmin, vmax=vmax, legend=True, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    \n",
    "    # remove axis of chart\n",
    "    fig.axis('off')\n",
    "    \n",
    "    # add a title\n",
    "    fig.set_title('Daily active COVID-19 cases\\nGreater Melbourne - ' + str(date), fontdict={'fontsize': '20','fontweight' : '3'})\n",
    "\n",
    "    # create an annotation for the  data source\n",
    "    fig.annotate('Data source: https://covidlive.com.au',\n",
    "        xy=(0.1, .08), xycoords='figure fraction',\n",
    "        horizontalalignment='left', verticalalignment='top',\n",
    "        fontsize=10, color='#555555')\n",
    "    \n",
    "    # this will save the figure as a high-res png in the output path. you can also save as svg if you prefer.\n",
    "    filepath = os.path.join(output_path, str(date) +'_covid_cases.jpg')\n",
    "    chart = fig.get_figure()\n",
    "    chart.savefig(filepath, dpi=350)\n",
    "    print(\"Saved image: \" + output_path + str(date) +'_covid_cases.jpg')\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing the GIF\n",
    "\n",
    "The GIF was created using https://gifmaker.me/\n",
    "All source images were uploaded to the above url."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
